\documentclass{article}

%\include{macros}

\bibliographystyle{plain}

\usepackage{epsfig}
\usepackage{xcolor}
%%\usepackage{amssymb}
\usepackage{amsmath}

\newcommand{\Abold}{{\bf A}}
\newcommand{\abold}{{\bf a}}
\newcommand{\bbold}{{\bf b}}
\newcommand{\cbold}{{\bf c}}
\newcommand{\dbold}{{\bf d}}
\newcommand{\ebold}{{\bf e}}
\newcommand{\fbold}{{\bf f}}
\newcommand{\Fbold}{{\bf F}}
\newcommand{\gbold}{{\bf g}}
\newcommand{\hbold}{{\bf h}}
\newcommand{\ibold}{{\bf i}}
\newcommand{\jbold}{{\bf j}}
\newcommand{\kbold}{{\bf k}}
\newcommand{\lbold}{{\bf l}}
\newcommand{\mbold}{{\bf m}}
\newcommand{\Mbold}{{\bf M}}
\newcommand{\nbold}{{\bf n}}
\newcommand{\obold}{{\bf o}}
\newcommand{\pbold}{{\bf p}}
\newcommand{\qbold}{{\bf q}}
\newcommand{\rbold}{{\bf r}}
\newcommand{\sbold}{{\bf s}}
\newcommand{\tbold}{{\bf t}}
\newcommand{\ubold}{{\bf u}}
\newcommand{\vbold}{{\bf v}}
\newcommand{\wbold}{{\bf w}}
\newcommand{\xbold}{{\bf x}}
\newcommand{\ybold}{{\bf y}}
\newcommand{\zbold}{{\bf z}}
\newcommand{\bigzbold}{{\bf Z}}
\newcommand{\xspace}{\hspace{2 mm}}

\newcommand{\ahat}{{\hat a}}
\newcommand{\bhat}{{\hat b}}
\newcommand{\chat}{{\hat c}}
\newcommand{\dhat}{{\hat d}}
\newcommand{\ehat}{{\hat e}}
\newcommand{\fhat}{{\hat f}}
\newcommand{\ghat}{{\hat g}}
\newcommand{\hhat}{{\hat h}}
\newcommand{\ihat}{{\hat i}}
\newcommand{\jhat}{{\hat j}}
\newcommand{\khat}{{\hat k}}
\newcommand{\lhat}{{\hat l}}
\newcommand{\mhat}{{\hat m}}
\newcommand{\nhat}{{\hat n}}
\newcommand{\ohat}{{\hat o}}
\newcommand{\phat}{{\hat p}}
\newcommand{\qhat}{{\hat q}}
\newcommand{\rhat}{{\hat r}}
\newcommand{\shat}{{\hat s}}
\newcommand{\that}{{\hat t}}
\newcommand{\uhat}{{\hat u}}
\newcommand{\vhat}{{\hat v}}
\newcommand{\what}{{\hat w}}
\newcommand{\xhat}{{\hat x}}
\newcommand{\yhat}{{\hat y}}
\newcommand{\zhat}{{\hat z}}

\newcommand{\abar}{{\bar {\bf a}}}
\newcommand{\bbar}{{\bar {\bf b}}}
\newcommand{\cbar}{{\bar {\bf c}}}
\newcommand{\dbar}{{\bar {\bf d}}}
\newcommand{\ebar}{{\bar {\bf e}}}
\newcommand{\fbar}{{\bar {\bf f}}}
\newcommand{\gbar}{{\bar {\bf g}}}
%\newcommand{\hbar}{{\bar {\bf h}}}
\newcommand{\ibar}{{\bar {\bf i}}}
\newcommand{\jbar}{{\bar {\bf j}}}
\newcommand{\kbar}{{\bar {\bf k}}}
\newcommand{\lbar}{{\bar {\bf l}}}
\newcommand{\mbar}{{\bar {\bf m}}}
\newcommand{\nbar}{{\bar {\bf n}}}
\newcommand{\obar}{{\bar {\bf o}}}
\newcommand{\pbar}{{\bar {\bf p}}}
\newcommand{\qbar}{{\bar {\bf q}}}
\newcommand{\rbar}{{\bar {\bf r}}}
\newcommand{\sbar}{{\bar {\bf s}}}
\newcommand{\tbar}{{\bar {\bf t}}}
\newcommand{\ubar}{{\bar {\bf u}}}
\newcommand{\vbar}{{\bar {\bf v}}}
\newcommand{\wbar}{{\bar {\bf w}}}
\newcommand{\xbar}{{\bar {\bf x}}}
\newcommand{\ybar}{{\bar {\bf y}}}
\newcommand{\zbar}{{\bar {\bf z}}}

\newcommand{\dx}{{h}}
\newcommand{\nph}{{n + \frac{1}{2}}}
\newcommand{\iph}{{\ibold + \frac{1}{2}\ebold_d}}
\newcommand{\ipmh}{{\ibold \pm \frac{1}{2}\ebold_d}}
\newcommand{\imh}{{\ibold - \frac{1}{2}\ebold_d}}

\newcommand{\half}{\frac{1}{2}}
%\newcommand{\Fbold}{\mathbf{F}}
%\newcommand{\iphed}{{\ibold+\half\ebold^d}}
\newcommand{\deriv}{\partial}
\newcommand{\area}{\mathcal{A}}
\newcommand{\R}[1]{\mathbb{R}^{#1}}
\newcommand{\cf}{{\scriptscriptstyle F}}
\newcommand{\cn}{{\scriptscriptstyle N}}
\newcommand{\sEB}{{\scriptscriptstyle EB}}
\renewcommand{\vec}[1]{\mathbf{#1}} % Vector (bold)
\newcommand{\tens}[1]{\mathbf{#1}} % Tensor (bold)
\newcommand{\mat}[1]{\mathbf{#1}} % Matrix (bold)
\newcommand{\hatvec}[1]{\hat{\vec{#1}}} % Vector with a hat (bold)
\newcommand{\ddt}[1]{\frac{\partial #1}{\partial t}} % partial d/dt
\newcommand{\DDt}[1]{\frac{\text{d}#1}{\text{d}t}} % "total" d/dt
\newcommand{\ddr}[1]{\frac{\partial #1}{\partial r}} % d/dr
\newcommand{\ddx}[1]{\frac{\partial #1}{\partial x}} % d/dx
\newcommand{\ddy}[1]{\frac{\partial #1}{\partial y}} % d/dy
\newcommand{\ddz}[1]{\frac{\partial #1}{\partial y}} % d/dz
\newcommand{\ddxi}[1]{\frac{\partial #1}{\partial x_i}} % d/dx_i
\newcommand{\diverg}[1]{\nabla\cdot#1} % Divergence operator
\newcommand{\curl}[1]{\nabla \times #1} % Curl operator
\newcommand{\dOmega}{\text{d}\Omega} % Volume differential (Omega style)
\newcommand{\dV}{\text{d}V} % Volume differential
\newcommand{\dA}{\text{d}A} % Area differential
\newcommand{\labelEq}[1]{\label{eq:#1}\hbox{\tt #1 \quad}} % Use this to label an equation.
\newcommand{\refEq}[1]{(\ref{eq:#1})}   % Use this to reference an equation.
\newcommand{\labelSec}[1]{\label{sec:#1}} % Use this to label a section.
\newcommand{\refSec}[1]{\S\ref{sec:#1}} % Use this to reference a section.
\newcommand{\labelChap}[1]{\label{chap:#1}} % Use this to label a chapter.
\newcommand{\refChap}[1]{Chapter \ref{chap:#1}} % Use this to reference a chapter.
\newcommand{\labelApp}[1]{\label{app:#1}} % Use this to label an appendix.
\newcommand{\refApp}[1]{Appendix \ref{app:#1}} % Use this to reference an appendix.
\newcommand{\ib}{{\bf{i}}}    % bold italic i
\newcommand{\jb}{{\bf{j}}}    % bold italic j
\newcommand{\kb}{{\bf{k}}}    % bold italic k
\newcommand{\lb}{{\bf{l}}}    % bold italic l
\newcommand{\mb}{{\bf{m}}}    % bold italic m
\newcommand{\ub}{{\bf{u}}}    % bold italic u
\newcommand{\xb}{{\bf{x}}}    % bold italic x
\newcommand{\vb}{{\bf{v}}}    % (bold italic) VoF index
\newcommand{\fb}{{\bf{f}}}    % (bold italic) face index
\newcommand{\pb}{{\bf{p}}}    % (bold italic) multi-index p
\newcommand{\qb}{{\bf{q}}}    % (bold italic) multi-index q
\newcommand{\ebd}{{\bf{e}^d}}
\newcommand{\normal}[1]{\vec{n}_{#1}} % Outward normal.
\newcommand{\order}[1]{\mathcal{O}(#1)} % Order notation



\newcommand{\ed}{{\bf{e}_d}}
\newcommand{\Zbold}{{\bf{0}}}
\newcommand{\unitV}{\mathds{1}}
\newcommand{\eb}{\text{EB}}
\newcommand{\EB}{\text{EB}}
\newcommand{\vol}{\mathcal{V}}
\newcommand{\face}{\mathcal{F}}
\newcommand{\zerobold}{{\bf{0}}}
\newcommand{\xz}{{\bf{x}_0}}

\newcommand{\Dim}{D}
\newcommand{\dif}{\mathrm{d}}
\newcommand{\dt}{{\Delta t}}
\newcommand{\avg}[1]{\overline{#1}}
\newcommand{\avgI}[1]{\overline{#1}_{\ibold}}
\newcommand{\imhed}{{\ibold+\frac{1}{2}\ebold_d}}
\newcommand{\ipmhj}{{\ibold\pm\frac{1}{2}\ebold_d}}
\newcommand{\iphj}{{\ibold+\frac{1}{2}\ebold_d}}
\newcommand{\imhj}{{\ibold-\frac{1}{2}\ebold_d}}

\newcommand{\ipfed}[1]{\ibold+\frac{#1}{2}\ebold_d}
\newcommand{\imfed}[1]{\ibold-\frac{#1}{2}\ebold_d}
\newcommand{\ipmfed}[1]{\ibold\pm\frac{#1}{2}\ebold_d}
\newcommand{\eq}[1]{(\ref{#1})}

\newcommand{\nref}{n_{\text{ref}}}
\newcommand{\phio}{\phi^{\circ}}

\begin{document}

\title{Polynomial expansions of finite volume data in a cut cell context}
\author{N. Overton-Katz \footnotemark[1]
   \and H. Johansen     \footnotemark[1]
   \and D. T. Graves    \footnotemark[1]
   \and D. Devendran    \footnotemark[2]
   \and O. Anteparra    \footnotemark[1]}

\maketitle

\begin{abstract}

  We discuss the mechanics of forming stable local polynomial
  expansions of finite volume data in the context of cut cell grids.
  We show that significant solvability issues can arise from certain weighting
  functions.    A very rudimentary but stable cell merger algorithm is
  presented as we present evidence that these solvability issues may be
  an artifact of small-cell instabilties.
  
\end{abstract}


\section{Introduction}

Embedded boundary (EB) grids are formed when one passes an  surface
through a Cartesian mesh.    For sufficiently complex geomtries, these methods
are very attactive because grid generation is a solved problem
and not computationally overwhelming even in a moving-boundary context
\cite{MillerTrebotich2012}.

In the current context, we form the cutting surface as the zero
surface of a function  of space $I(\xbold)$, $\xbold \in R^D$.
For smooth ($I$),  moments can be generated to any
accuracy \cite{Schwartz2015}.

EB grids can contain volumes that are arbitrarily small.    This
"small-cell problem'' produces
algorithmic difficulties that generations of researchers have labored
to overcome with great success.   EB methods are used for high speed
compressible flows \cite{Colella2006, Graves2013} and for
slower, incompressible applications \cite{Trebotich2015} and conjugate
heat transfer \cite{Crockett2010}.

Formally, the underlying description of space
is given by rectangular control volumes on a Cartesian mesh
$\Upsilon_\ibold = [(\ibold-\half {\ubold})h, (\ibold+\half
{\ubold})h], \ibold \in \bigzbold^D$, where $D$ is the dimensionality
of the problem, $h$ is the mesh spacing, and ${\ubold}$ is the vector
whose entries are all one (note we use bold font $\ubold = (u_1, \dots, u_d,
\dots, u_D)$ to indicate a vector quantity).
Given an irregular domain $\Omega$, we
obtain control volumes $V_\ibold = \Upsilon_\ibold \bigcap \Omega$ and
faces $A_{\ibold,d\pm} = A_{\ibold \pm \half \ebold_d}$ which are the
intersection of the boundary of $\partial V_\ibold$ with the
coordinate planes $\{{\xbold}:x_d = (i_d \pm \half)h \}$ ($\ebold_d$ is
the unit vector in the $d$ direction).  We also
define $A_{B,\ibold}$ to be the intersection of the boundary of the
irregular domain with the Cartesian control volume: $A_{B,\ibold}
= \partial \Omega \bigcap \Upsilon_\ibold$. 


\section {Finite volume notation}

Throughout this paper, we use the following compact notation:
\begin{align*}
(\xbold - \xbar)^\pbold &= \prod\limits^D_{d=1} (x_d - {\bar x}_d)^{p_d} \\
\pbold! &= \prod\limits^D_{d = 1} p_d!
\end{align*}
Given a point in space $\xbar$, and a $D$-dimensional integer vector
$\pbold$, we define $m_v^\pbold(\xbar)$ to be the $\pbold^{th}$
moment of the volume $V$ relative to the point $\xbar$.
\begin{equation}
m_v^\pbold(\xbar)  =  \int\limits_{V} (\xbold - \xbar)^\pbold dV
\label{eqn::volmoment}
\end{equation}

 
Given a sufficiently smooth function $\psi$, we can approximate $\psi$
in the neighborhood of $\xbar$ using a Taylor expansion to order $P$:
\begin{equation}
\psi(\xbold)  =  \sum\limits_{p < P} C^p (\xbar - \xbar)^p \label{eqn::taylor}
\end{equation}
where $C^p$ this appropriate Taylor coefficient.  In three dimensions,
\begin{equation}
  C^p =\frac{1}{p!}
      \frac{\partial^{p_0}}{\partial x_0}
      \frac{\partial^{p_1}}{\partial x_1}
      \frac{\partial^{p_2}}{\partial x_2}  (\psi).
\end{equation}  
In finite volume  methods, we define grid data to be
averages over volumes.   So if we discretize the smooth function
$\psi$, the average over the volume $\ibold$ is given by
\begin{equation*}
 V_\ibold <\psi>_\ibold = \int\limits_{V_\ibold} \psi(\xbold) dV
\end{equation*}
If we insert the Taylor expansion \ref{eqn::taylor}, we get a discrete
approximation to the smooth function $\psi$ that is accurate to order $P$.
\begin{equation*}
 V_\ibold <\psi>_\ibold = \sum\limits_{p < P} C^p m^p. 
\end{equation*}
This forms a local polynomial expansion of $\psi$ around the volume
$\ibold$ expressed in terms moments ($m$) which are the natural
products of grid generation.  Modern, higher order embedded boundary
methods use this description directly to generate stencils
\cite{Overton2022a, Devendran2017, Schwartz2015}.  At the
core, all these algorithms have a similar procedure for finding the
Taylor coefficients $C^p$ which is worth discussing. 

The discerning reader will notice that
the equation set used to create $C$ only includes the volume
equations.  Devendran \cite{Devendran2017} also include boundary
condition equations in the equation set.  For simple enough boundary
conditions, this works very well.  There are many equation sets,
however, which do not lend themselves easily to this approach.
Notably, hyperbolic equations often have boundary conditions which are
fomulated in terms of characteristic variables.  Using this
information in the system of equations for Taylor coefficients is
still a matter of research.  We therefore believe that restricting
ourselves to the volume equations can provide insight valuable to
developers of this class of algorithms.

\section{Computing Taylor coefficients and Matrix Conditioning}

Consider a finite volume grid where we know all geometric moments to
order $P$.  Given values of $<\psi>$ everwhere on the grid, we wish to
approximate the Taylor coefficients at a volume $\ibold$ given that we
know $\cn_\ibold = \{\jbold\}$, the set of $N_v$ closest neighbors of
the volume $\ibold$.  Using the Taylor expansion at each point gives
us $N_v$ equations for $C^p$
\begin{equation}
  V_\jbold <\psi>_\jbold = \sum\limits_{p < P} C^p_\ibold m^p_\jbold.
\end{equation}
Let's say there are $N_p$ Taylor coefficients.  We can force $N_v >
N_p$ by getting a large enough neighborhood.  This means that we have
an overdetermined system of the form
\begin{equation*}
M C = P 
\end{equation*}
where $M = \{\{m^{pi}_\jbold\}\}$, $C=\{C^p\}$,  and $P= \{<\psi_\jbold>\}$.
Since the system is overdetermined, we can introduce a 
meaningful weighting matrix $W$ \footnotemark[3].  Choice of $W$
is crucial to the stability of these algorithms
\footnotemark[4].
We multiply and solve
\begin{equation*}
WMC = WP.
\end{equation*}
Since these matricies are (deliberately) not square, we approximate
the solution using a Moore-Penrose pseudo-inverse:
\begin{equation*}
C = ((WM)^T(WM))^{-1} (WM)^T P.
\end{equation*}
The matrix inversion at the heart of this method requires that we need
know to what degree the matrix $A \equiv (WM)^T(WM)$ is
well-conditioned.  Experience suggests that small cells play a role in
that conditioning and that the weighting matrix $W$ can be used to
mitigate conditioning issues that unweighted least squares may
produce.

To explore the roles of small cells and weighting functions, we first
introduce a merged cut cell space where there are no small cells.
This merged space still has geometric moments accurate to the same order 
as the original cut cell space.

We study how weighting matricies change the conditioning of $A$.  This is
done both with and without cell merger in the hope hope that this
exploration may lead to simpler, more robust cut cell algorithms to
solve partial differential equations at high order.

\section{Cell Merger Algorithm}

We use a very simple cell merger algorithm.  Given a cut cell
$\ibold$, we define the box containing only that cell
$B_c = B(\ibold, \ibold)$ 
We form a $2^D$ cell rectangular region
by coarsening and then refining $B_c$ to form $B_v = R(C(B_c))$
\footnotemark[6].
After that process, any left over small cells are merged with their
biggest neighbor.    See figures \ref{fig::unmerged2dmap} and
\ref{fig::merged2dmap} for a simple example of how this algorithm
creates fairly chunky grids   \footnotemark[5].

We define the volume fraction $\kappa_\ibold \equiv  V_\ibold/h^D$.
For unmerged grids, $ 0 < \kappa <= 1$.   When merged using this
algorithm, $\kappa$ can be larger than $2^D$.   

\begin{figure}
\centerline{\epsfig{figure=unmerged.ps,width=0.4\linewidth }} 
\caption{Map for EB grid produced by a cutting cirle. $\kappa <= 1$.
  Each cut cell has a unique positive integer.}
\end{figure}

\begin{figure}
\centerline{\epsfig{figure=merged.ps,width=0.4\linewidth } }
\label{fig::merged2dmap}
\caption{Map of EB grid shown in \ref{fig::unmerged2dmap} after using
  cell merger algorithm.
  Each cut cell has a unique positive integer. $\kappa <= 4.1433$}
\end{figure}

\footnotetext[1]{Lawrence Berkeley National Laboratory, Berkeley,
  CA. Research at LBNL was supported financially by the Office of
  Advanced Scientific Computing Research of the US Department of
  Energy under contract number DE-AC02-05CH11231.}
\footnotetext[2]{Ford Motor Company, Sunnyvale, CA.}
\footnotetext[3]{If the matrix $M$ is square, a weighting matrix can
  have no effect and the Moore-Penrose psueudoinverse becomes
  $M^{-1}$.}

\footnotetext[4]{Defining $\xbar_\ibold = 0$, the
  equations for volumes $\jbold$ where $\xbar_\jbold$ target receive
  higher weights.  Diagonal weighting matricies are common.  Usually,
  these algorithms define a distance metric $D(\ibold, \jbold)$ for
  two volumes $\ibold$ and $\jbold$.  Typically they make
  $W_{\jbold,\jbold}$ decrease strongly with increasing $D(\ibold,
  \jbold)$ to assign higher importance to the equations for volumes
  closer to $\ibold$.  Devendran for example \cite{Devendran2017},
  uses a weighting function that varies with $W_{\ibold,\jbold}
  \approx 1./D(\ibold,\jbold)^5$ }.

\footnotetext[5] {Merging two cells is simply a matter of removing the
  intervening faces, shifting all moments them to a common location
  and adding them together.  No accuracy is lost in this process
  outside of the fact that we have fewer degress of freedom because
  semantically, we are just adding volume integrals over distinct
  volumes, which is exact.}

\footnotetext[6] {We mean a Box as defined in Chombo, a subset of
  $Z^D$.  Coarsening and refining has the standard Chombo semantic
  \cite{ChomboDesign, ChomboDesignEB}.}

\renewcommand{\thefootnote}{\fnsymbol{footnote}}\
\bibliography{references}

\end{document}
