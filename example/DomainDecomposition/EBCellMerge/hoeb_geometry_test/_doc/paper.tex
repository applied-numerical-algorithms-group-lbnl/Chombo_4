\documentclass{article}

%\include{macros}

\bibliographystyle{plain}

\usepackage{epsfig}
\usepackage{xcolor}
%%\usepackage{amssymb}
\usepackage{amsmath}

\newcommand{\Abold}{{\bf A}}
\newcommand{\abold}{{\bf a}}
\newcommand{\bbold}{{\bf b}}
\newcommand{\cbold}{{\bf c}}
\newcommand{\dbold}{{\bf d}}
\newcommand{\ebold}{{\bf e}}
\newcommand{\fbold}{{\bf f}}
\newcommand{\Fbold}{{\bf F}}
\newcommand{\gbold}{{\bf g}}
\newcommand{\hbold}{{\bf h}}
\newcommand{\ibold}{{\bf i}}
\newcommand{\jbold}{{\bf j}}
\newcommand{\kbold}{{\bf k}}
\newcommand{\lbold}{{\bf l}}
\newcommand{\mbold}{{\bf m}}
\newcommand{\Mbold}{{\bf M}}
\newcommand{\nbold}{{\bf n}}
\newcommand{\obold}{{\bf o}}
\newcommand{\pbold}{{\bf p}}
\newcommand{\qbold}{{\bf q}}
\newcommand{\rbold}{{\bf r}}
\newcommand{\sbold}{{\bf s}}
\newcommand{\tbold}{{\bf t}}
\newcommand{\ubold}{{\bf u}}
\newcommand{\vbold}{{\bf v}}
\newcommand{\wbold}{{\bf w}}
\newcommand{\xbold}{{\bf x}}
\newcommand{\ybold}{{\bf y}}
\newcommand{\zbold}{{\bf z}}
\newcommand{\bigzbold}{{\bf Z}}
\newcommand{\xspace}{\hspace{2 mm}}

\newcommand{\ahat}{{\hat a}}
\newcommand{\bhat}{{\hat b}}
\newcommand{\chat}{{\hat c}}
\newcommand{\dhat}{{\hat d}}
\newcommand{\ehat}{{\hat e}}
\newcommand{\fhat}{{\hat f}}
\newcommand{\ghat}{{\hat g}}
\newcommand{\hhat}{{\hat h}}
\newcommand{\ihat}{{\hat i}}
\newcommand{\jhat}{{\hat j}}
\newcommand{\khat}{{\hat k}}
\newcommand{\lhat}{{\hat l}}
\newcommand{\mhat}{{\hat m}}
\newcommand{\nhat}{{\hat n}}
\newcommand{\ohat}{{\hat o}}
\newcommand{\phat}{{\hat p}}
\newcommand{\qhat}{{\hat q}}
\newcommand{\rhat}{{\hat r}}
\newcommand{\shat}{{\hat s}}
\newcommand{\that}{{\hat t}}
\newcommand{\uhat}{{\hat u}}
\newcommand{\vhat}{{\hat v}}
\newcommand{\what}{{\hat w}}
\newcommand{\xhat}{{\hat x}}
\newcommand{\yhat}{{\hat y}}
\newcommand{\zhat}{{\hat z}}

\newcommand{\abar}{{\bar {\bf a}}}
\newcommand{\bbar}{{\bar {\bf b}}}
\newcommand{\cbar}{{\bar {\bf c}}}
\newcommand{\dbar}{{\bar {\bf d}}}
\newcommand{\ebar}{{\bar {\bf e}}}
\newcommand{\fbar}{{\bar {\bf f}}}
\newcommand{\gbar}{{\bar {\bf g}}}
%\newcommand{\hbar}{{\bar {\bf h}}}
\newcommand{\ibar}{{\bar {\bf i}}}
\newcommand{\jbar}{{\bar {\bf j}}}
\newcommand{\kbar}{{\bar {\bf k}}}
\newcommand{\lbar}{{\bar {\bf l}}}
\newcommand{\mbar}{{\bar {\bf m}}}
\newcommand{\nbar}{{\bar {\bf n}}}
\newcommand{\obar}{{\bar {\bf o}}}
\newcommand{\pbar}{{\bar {\bf p}}}
\newcommand{\qbar}{{\bar {\bf q}}}
\newcommand{\rbar}{{\bar {\bf r}}}
\newcommand{\sbar}{{\bar {\bf s}}}
\newcommand{\tbar}{{\bar {\bf t}}}
\newcommand{\ubar}{{\bar {\bf u}}}
\newcommand{\vbar}{{\bar {\bf v}}}
\newcommand{\wbar}{{\bar {\bf w}}}
\newcommand{\xbar}{{\bar {\bf x}}}
\newcommand{\ybar}{{\bar {\bf y}}}
\newcommand{\zbar}{{\bar {\bf z}}}

\newcommand{\dx}{{h}}
\newcommand{\nph}{{n + \frac{1}{2}}}
\newcommand{\iph}{{\ibold + \frac{1}{2}\ebold_d}}
\newcommand{\ipmh}{{\ibold \pm \frac{1}{2}\ebold_d}}
\newcommand{\imh}{{\ibold - \frac{1}{2}\ebold_d}}

\newcommand{\half}{\frac{1}{2}}
%\newcommand{\Fbold}{\mathbf{F}}
%\newcommand{\iphed}{{\ibold+\half\ebold^d}}
\newcommand{\deriv}{\partial}
\newcommand{\area}{\mathcal{A}}
\newcommand{\R}[1]{\mathbb{R}^{#1}}
\newcommand{\cf}{{\scriptscriptstyle F}}
\newcommand{\cn}{{\scriptscriptstyle N}}
\newcommand{\sEB}{{\scriptscriptstyle EB}}
\renewcommand{\vec}[1]{\mathbf{#1}} % Vector (bold)
\newcommand{\tens}[1]{\mathbf{#1}} % Tensor (bold)
\newcommand{\mat}[1]{\mathbf{#1}} % Matrix (bold)
\newcommand{\hatvec}[1]{\hat{\vec{#1}}} % Vector with a hat (bold)
\newcommand{\ddt}[1]{\frac{\partial #1}{\partial t}} % partial d/dt
\newcommand{\DDt}[1]{\frac{\text{d}#1}{\text{d}t}} % "total" d/dt
\newcommand{\ddr}[1]{\frac{\partial #1}{\partial r}} % d/dr
\newcommand{\ddx}[1]{\frac{\partial #1}{\partial x}} % d/dx
\newcommand{\ddy}[1]{\frac{\partial #1}{\partial y}} % d/dy
\newcommand{\ddz}[1]{\frac{\partial #1}{\partial y}} % d/dz
\newcommand{\ddxi}[1]{\frac{\partial #1}{\partial x_i}} % d/dx_i
\newcommand{\diverg}[1]{\nabla\cdot#1} % Divergence operator
\newcommand{\curl}[1]{\nabla \times #1} % Curl operator
\newcommand{\dOmega}{\text{d}\Omega} % Volume differential (Omega style)
\newcommand{\dV}{\text{d}V} % Volume differential
\newcommand{\dA}{\text{d}A} % Area differential
\newcommand{\labelEq}[1]{\label{eq:#1}\hbox{\tt #1 \quad}} % Use this to label an equation.
\newcommand{\refEq}[1]{(\ref{eq:#1})}   % Use this to reference an equation.
\newcommand{\labelSec}[1]{\label{sec:#1}} % Use this to label a section.
\newcommand{\refSec}[1]{\S\ref{sec:#1}} % Use this to reference a section.
\newcommand{\labelChap}[1]{\label{chap:#1}} % Use this to label a chapter.
\newcommand{\refChap}[1]{Chapter \ref{chap:#1}} % Use this to reference a chapter.
\newcommand{\labelApp}[1]{\label{app:#1}} % Use this to label an appendix.
\newcommand{\refApp}[1]{Appendix \ref{app:#1}} % Use this to reference an appendix.
\newcommand{\ib}{{\bf{i}}}    % bold italic i
\newcommand{\jb}{{\bf{j}}}    % bold italic j
\newcommand{\kb}{{\bf{k}}}    % bold italic k
\newcommand{\lb}{{\bf{l}}}    % bold italic l
\newcommand{\mb}{{\bf{m}}}    % bold italic m
\newcommand{\ub}{{\bf{u}}}    % bold italic u
\newcommand{\xb}{{\bf{x}}}    % bold italic x
\newcommand{\vb}{{\bf{v}}}    % (bold italic) VoF index
\newcommand{\fb}{{\bf{f}}}    % (bold italic) face index
\newcommand{\pb}{{\bf{p}}}    % (bold italic) multi-index p
\newcommand{\qb}{{\bf{q}}}    % (bold italic) multi-index q
\newcommand{\ebd}{{\bf{e}^d}}
\newcommand{\normal}[1]{\vec{n}_{#1}} % Outward normal.
\newcommand{\order}[1]{\mathcal{O}(#1)} % Order notation



\newcommand{\ed}{{\bf{e}_d}}
\newcommand{\Zbold}{{\bf{0}}}
\newcommand{\unitV}{\mathds{1}}
\newcommand{\eb}{\text{EB}}
\newcommand{\EB}{\text{EB}}
\newcommand{\vol}{\mathcal{V}}
\newcommand{\face}{\mathcal{F}}
\newcommand{\zerobold}{{\bf{0}}}
\newcommand{\xz}{{\bf{x}_0}}

\newcommand{\Dim}{D}
\newcommand{\dif}{\mathrm{d}}
\newcommand{\dt}{{\Delta t}}
\newcommand{\avg}[1]{\overline{#1}}
\newcommand{\avgI}[1]{\overline{#1}_{\ibold}}
\newcommand{\imhed}{{\ibold+\frac{1}{2}\ebold_d}}
\newcommand{\ipmhj}{{\ibold\pm\frac{1}{2}\ebold_d}}
\newcommand{\iphj}{{\ibold+\frac{1}{2}\ebold_d}}
\newcommand{\imhj}{{\ibold-\frac{1}{2}\ebold_d}}

\newcommand{\ipfed}[1]{\ibold+\frac{#1}{2}\ebold_d}
\newcommand{\imfed}[1]{\ibold-\frac{#1}{2}\ebold_d}
\newcommand{\ipmfed}[1]{\ibold\pm\frac{#1}{2}\ebold_d}
\newcommand{\eq}[1]{(\ref{#1})}

\newcommand{\nref}{n_{\text{ref}}}
\newcommand{\phio}{\phi^{\circ}}

\begin{document}

\title{Polynomial expansions of finite volume data in a cut cell context}
\author{N. Overton-Katz \footnotemark[1]
   \and H. Johansen     \footnotemark[1]
   \and D. T. Graves    \footnotemark[1]
   \and D. Devendran    \footnotemark[2]
   \and O. Anteparra    \footnotemark[1]}

\maketitle

\begin{abstract}

  We discuss the mechanics of forming stable local polynomial
  expansions of finite volume data in the context of cut cell grids.
  We show that significant solvability issues can arise from certain weighting
  functions.    A very rudimentary but stable cell merger algorithm is
  presented as we present evidence that these solvability issues may be
  an artifact of small-cell instabilties.
  
\end{abstract}


\section{Introduction}

Embedded boundary (EB) grids are formed when one passes an  surface
through a Cartesian mesh.    For sufficiently complex geomtries, these methods
are very attactive because grid generation is a solved problem
and not computationally overwhelming even in a moving-boundary context
\cite{MillerTrebotich2012}.

In the current context, we form the cutting surface as the zero
surface of a function  of space $I(\xbold)$, $\xbold \in R^D$.
For smooth ($I$),  moments can be generated to any
accuracy \cite{Schwartz2015}.

EB grids can contain volumes that are arbitrarily small.    This
"small-cell problem'' produces
algorithmic difficulties that generations of researchers have labored
to overcome with great success.   EB methods are used for high speed
compressible flows \cite{Colella2006, Graves2013} and for
slower, incompressible applications \cite{Trebotich2015} and conjugate
heat transfer \cite{Crockett2010}.

Formally, the underlying description of space
is given by rectangular control volumes on a Cartesian mesh
$\Upsilon_\ibold = [(\ibold-\half {\ubold})h, (\ibold+\half
{\ubold})h], \ibold \in \bigzbold^D$, where $D$ is the dimensionality
of the problem, $h$ is the mesh spacing, and ${\ubold}$ is the vector
whose entries are all one (note we use bold font $\ubold = (u_1, \dots, u_d,
\dots, u_D)$ to indicate a vector quantity).
Given an irregular domain $\Omega$, we
obtain control volumes $V_\ibold = \Upsilon_\ibold \bigcap \Omega$ and
faces $A_{\ibold,d\pm} = A_{\ibold \pm \half \ebold_d}$ which are the
intersection of the boundary of $\partial V_\ibold$ with the
coordinate planes $\{{\xbold}:x_d = (i_d \pm \half)h \}$ ($\ebold_d$ is
the unit vector in the $d$ direction).  We also
define $A_{B,\ibold}$ to be the intersection of the boundary of the
irregular domain with the Cartesian control volume: $A_{B,\ibold}
= \partial \Omega \bigcap \Upsilon_\ibold$. 


\section {Finite volume notation}

Throughout this paper, we use the following compact notation:
\begin{align*}
(\xbold - \xbar)^\pbold &= \prod\limits^D_{d=1} (x_d - {\bar x}_d)^{p_d} \\
\pbold! &= \prod\limits^D_{d = 1} p_d!
\end{align*}
Given a point in space $\xbar$, and a $D$-dimensional integer vector
$\pbold$, we define $m_v^\pbold(\xbar)$ to be the $\pbold^{th}$
moment of the volume $V$ relative to the point $\xbar$.
\begin{equation}
m_v^\pbold(\xbar)  =  \int\limits_{V} (\xbold - \xbar)^\pbold dV
\label{eqn::volmoment}
\end{equation}

 
Given a sufficiently smooth function $\psi$, we can approximate $\psi$
in the neighborhood of $\xbar$ using a Taylor expansion to order $P_T$:
\begin{equation}
\psi(\xbold)  =  \sum\limits_{p < P_T} C^p (\xbar -\xbar)^p
\label{eqn::taylor}
\end{equation}
where $C^p$ this appropriate Taylor coefficient.  In three dimensions,
\begin{equation}
  C^p =\frac{1}{p!}
      \frac{\partial^{p_0}}{\partial x_0}
      \frac{\partial^{p_1}}{\partial x_1}
      \frac{\partial^{p_2}}{\partial x_2}  (\psi).
\end{equation}  
In finite volume  methods, we define grid data to be
averages over volumes.   So if we discretize the smooth function
$\psi$, the average over the volume $\ibold$ is given by
\begin{equation*}
 V_\ibold <\psi>_\ibold = \int\limits_{V_\ibold} \psi(\xbold) dV
\end{equation*}
If we insert the Taylor expansion \ref{eqn::taylor}, we get a discrete
approximation to the smooth function $\psi$ that is accurate to order $P_T$.
\begin{equation*}
 V_\ibold <\psi>_\ibold = \sum\limits_{p < P_T} C^p m^p. 
\end{equation*}
This forms a local polynomial expansion of $\psi$ around the volume
$\ibold$ expressed in terms moments ($m$) which are the natural
products of grid generation.  Modern, higher order embedded boundary
methods use this description directly to generate stencils
\cite{Overton2022a, Devendran2017, Schwartz2015}.  At the
core, all these algorithms have a similar procedure for finding the
Taylor coefficients $C^p$ which is worth discussing.  \footnotemark[8]


\section{Computing Taylor coefficients and Matrix Conditioning}

Consider a finite volume grid where we know all geometric moments to
order $P_T$.  Given values of $<\psi>$ everwhere on the grid, we wish to
approximate the Taylor coefficients at a volume $\ibold$ given that we
know $\cn_\ibold = \{\jbold\}$, the set of $N_v$ closest neighbors of
the volume $\ibold$.  Using the Taylor expansion at each point gives
us $N_v$ equations for $C^p$
\begin{equation}
  V_\jbold <\psi>_\jbold = \sum\limits_{p < P_T} C^p_\ibold m^p_\jbold.
\end{equation}
Let's say there are $N_p$ Taylor coefficients.  We can force $N_v >
N_p$ by getting a large enough neighborhood.  This means that we have
an overdetermined system of the form
\begin{equation*}
M C = P 
\end{equation*}
where $M = \{\{m^{pi}_\jbold\}\}$, $C=\{C^p\}$,  and $P= \{<\psi_\jbold>\}$.
Since the system is overdetermined, we can introduce a 
meaningful weighting matrix $W$ \footnotemark[3].  Choice of $W$
is crucial to the stability of these algorithms
\footnotemark[4].
We multiply and solve
\begin{equation*}
WMC = WP.
\end{equation*}
Since these matricies are (deliberately) not square, we approximate
the solution using a Moore-Penrose pseudo-inverse:
\begin{equation}
  C = ((WM)^T(WM))^{-1} (WM)^T P.
\label{eqn::getC}  
\end{equation}
This formulation can woven into the computation for stencil
components;  Devendran \cite{Devendran2017}, for example, explains the
process for Poisson's equation.

Unfortunately, the matrix $A \equiv (WM)^T(WM)$ can be poorly conditioned.
That these algorithms can invert a poorly-conditioned matrix to compute
stencil coefficients introduces an interesting type of uncertainty: error in
the very coefficients of a stencil operation.   If the matrix is poorly
conditioned, the coefficients of the stencil can only be known to
limited precision.   This lack of precision is measurable as are its
consequences.

Broadly speaking, there are two approaches to dealing with this poor
conditioning. One can improve the accuracy of the matrix
representation so she can absorb the reduction in precision and still
produce coefficients of sufficient accuracy.
Lo, et al. \cite{Lo2019} show good results using quad-precision arithmetic
for matrices which produce double precision coefficients.
The other approach is to improve the
conditioning of the matrix by careful choices of weighting matrix and
neighborhood.  


\section{Condition number measurements}

To gain insight into the connection between solvability, weighting and
order, we evaluate the matrix $A \equiv (WM)^T(WM)$
at every volume in a computational grid and analyze its
eigenvalues.   Given a matrix $A_i$ with the set of eigenvalues
$\{ \lambda_{i}\}$, the inverse of the condition number $I_i$ is given by
\begin{equation*}
  I_i = \frac{\lambda_i|_{min}}{\lambda_i|_{max}},
\end{equation*}
which goes to zero as the maximum and minimum eigenvalues diverge and
the matrix becomes more poorly conditioned.   These eigenvalues are
obtained through  SVD decompostion \footnotemark[7].

First we  measure   an uncut, Cartesian mesh to
provide a baseline without the complications involved with cut cells.
Next we cut the mesh with a very smooth implicit function and do the
same measurements.   Finally we take this cut mesh and merge its small
cells to neighbors to eliminate all cells smaller than a Cartesian
volume to isolate the effects of small cells.

All volumes $V_i$ start with a index $i \in Z^D$.
We start from volume $V_0$.   For 
weighting function, we need to measure $D_{w, V_0}(V_1)$,
the Manhattan disance to the volume $V_1$:
\begin{equation}
  D_{W, V_0}(V_1) = \sum\limits_{d \in {1...D}} |i_1^d - i_0^d|.
\label{eqn::uptownFunk}
\end{equation}
We define $W_{v_0}(V_1)$, the weighting function used by volume $V_0$ for the
equation describing  volume $V_1$ we use is given by
\begin{equation}
  W_{v_0}(V_1)  \equiv \frac{1}{D^{P_w}_{V_0}(V_1)},
\label{eqn::weightFunk}  
\end{equation}
where we vary $P_w$, and the 
polynomial order $P_T$.

\subsection{All Regular geometry}

We begin with the simplest possible motivating example: a
$D$-dimensional Cartesian geometry wherein all cells are uncut.
Figure \ref{fig::T3W3} shows all values of $I$ for $D=2$, $I$ with
$P_w = P_T = 3$.  Table \ref{tab::worst_all_reg_inv_conv} shows the
worst condition number in this simple grid for a number of values of
$P_w$ and $P_T$.  We show first that for a safe (low) choice of
$P_T$, even the worst condition number in a given grid can be quite
reasonable. With more aggressive choices of $P_T$, $I$ can be quite
small (especially near the domain boundaries).  The data also
show clearly that there is a connection between solvability, weighting
function, and polynomial order.  Unexpectedly, we show that for a
fixed polynomial order $P_T$, a higher weighting power $P_w$ can make the
solvability problem worse.

\begin{figure}
\centerline{\epsfig{figure=_fig/all_reg_t3_w3_inv_cond.ps,width=0.4\linewidth } }
\label{fig::T3W3}
\caption
    {
      $I$ (inverse of the condition number for matrix $A$ for a $32^2$
      uncut grid where $P_w = P_T = 3$.
    }
\end{figure}


\begin{table}
\begin{center}
\begin{tabular}{|cccc|ccc|} \hline
$D$ $P^T$  & $P^W$ & $R_s$ & $\lambda_{max}$ & $\lambda_{min}$   & $I$ \\
  \hline
2 & 1 & 1 & 3 & 2.280975e+00 & 1.471897e-03 & 6.452929e-04 \\ 
2 & 1 & 2 & 3 & 1.184453e+00 & 1.544110e-04 & 1.303648e-04 \\ 
2 & 1 & 3 & 3 & 1.036586e+00 & 2.327227e-05 & 2.245088e-05 \\ 
2 & 1 & 4 & 3 & 1.008340e+00 & 4.569664e-06 & 4.531869e-06 \\ 
2 & 1 & 5 & 3 & 1.002008e+00 & 1.029556e-06 & 1.027493e-06 \\ 
2 & 2 & 1 & 3 & 2.280983e+00 & 1.185321e-06 & 5.196535e-07 \\ 
2 & 2 & 2 & 3 & 1.184453e+00 & 8.194451e-08 & 6.918341e-08 \\ 
2 & 2 & 3 & 3 & 1.036586e+00 & 5.067663e-09 & 4.888801e-09 \\ 
2 & 2 & 4 & 3 & 1.008340e+00 & 3.385548e-10 & 3.357547e-10 \\ 
2 & 2 & 5 & 3 & 1.002008e+00 & 2.634337e-11 & 2.629058e-11 \\ 
2 & 3 & 1 & 3 & 2.280983e+00 & 5.060791e-10 & 2.218689e-10 \\ 
2 & 3 & 2 & 3 & 1.184453e+00 & 4.179917e-11 & 3.528985e-11 \\ 
2 & 3 & 3 & 3 & 1.036586e+00 & 2.762010e-12 & 2.664525e-12 \\ 
2 & 3 & 4 & 3 & 1.008340e+00 & 1.380647e-13 & 1.369228e-13 \\ 
2 & 3 & 5 & 3 & 1.002008e+00 & 6.886907e-15 & 6.873105e-15 \\ 
2 & 4 & 1 & 3 & 2.744326e+00 & 2.848432e-25 & 1.037935e-25 \\ 
2 & 4 & 2 & 3 & 1.184453e+00 & 1.481174e-27 & 1.250513e-27 \\ 
2 & 4 & 3 & 3 & 1.055930e+00 & 4.257688e-26 & 4.032168e-26 \\ 
2 & 4 & 4 & 3 & 1.008340e+00 & 1.078564e-23 & 1.069643e-23 \\ 
2 & 4 & 5 & 3 & 1.002008e+00 & 5.873348e-25 & 5.861578e-25 \\ 
3 & 1 & 1 & 3 & 4.207341e+00 & 3.347096e-03 & 7.955372e-04 \\ 
3 & 1 & 2 & 3 & 1.335375e+00 & 2.299835e-04 & 1.722239e-04 \\ 
3 & 1 & 3 & 3 & 1.058688e+00 & 2.726319e-05 & 2.575186e-05 \\ 
3 & 1 & 4 & 3 & 1.012826e+00 & 4.843834e-06 & 4.782494e-06 \\ 
3 & 1 & 5 & 3 & 1.003042e+00 & 1.052599e-06 & 1.049406e-06 \\ 
3 & 2 & 1 & 3 & 4.207383e+00 & 2.698941e-06 & 6.414775e-07 \\ 
3 & 2 & 2 & 3 & 1.335376e+00 & 1.349331e-07 & 1.010450e-07 \\ 
3 & 2 & 3 & 3 & 1.058688e+00 & 6.504992e-09 & 6.144388e-09 \\ 
3 & 2 & 4 & 3 & 1.012826e+00 & 3.782273e-10 & 3.734376e-10 \\ 
3 & 2 & 5 & 3 & 1.003042e+00 & 2.753365e-11 & 2.745014e-11 \\ 
3 & 3 & 1 & 3 & 4.207383e+00 & 1.150489e-09 & 2.734453e-10 \\ 
3 & 3 & 2 & 3 & 1.335376e+00 & 6.641096e-11 & 4.973204e-11 \\ 
3 & 3 & 3 & 3 & 1.058688e+00 & 3.224905e-12 & 3.046133e-12 \\ 
3 & 3 & 4 & 3 & 1.012826e+00 & 1.004670e-13 & 9.919476e-14 \\ 
3 & 3 & 5 & 3 & 1.003042e+00 & 3.476637e-15 & 3.466092e-15 \\ 
3 & 4 & 1 & 3 & 5.166875e+00 & 1.524000e-25 & 2.949559e-26 \\ 
3 & 4 & 2 & 3 & 1.474014e+00 & 1.231139e-27 & 8.352288e-28 \\ 
3 & 4 & 3 & 3 & 1.102368e+00 & 5.433012e-27 & 4.928491e-27 \\ 
3 & 4 & 4 & 3 & 1.012826e+00 & 1.327379e-23 & 1.310570e-23 \\ 
3 & 4 & 5 & 3 & 1.003042e+00 & 6.807789e-25 & 6.787141e-25 \\ 
\hline
\label{tab::worst_all_reg_inv_conv}
\end{tabular}
\end{center}
\caption
    {
      We show the lowest value 
      $I$ for an entire Cartesian grid of size $32^D$.
      We vary Taylor power $P^T$, weighting
      function exponents $P^W$, and dimensionality $D$. 
    }
\end{table}

\section{Cut Cell Geometry}
\label{sec::eb}
Our next  grid is a Cartesian grid cut  by a sphere (or a circle in two
dimensions). The computational domain is the unit cube.   The cutting
sphere center is the center of the cube.   The radius of the cutting
sphere is 0.45.  The grid moments are generated using the algorithm
specified in \cite{Schwartz2015}.  The moments are accurate to
order $h^{P^T}$.   The map for the 2D case is shown in figure
\ref{fig::unmerged2dmap}.

\begin{figure}
\centerline{\epsfig{figure=_fig/unmerged.ps,width=0.4\linewidth }} 
\caption
    {
      Map for EB grid produced by a cutting cirle. $0 <  \kappa <= 1$.
  Each cut cell has a unique positive integer.}
\label{fig::unmerged2dmap}
\end{figure}


\subsection{Merged Geometry}

Our next  grid is a the same grid show in section \ref{sec::eb}.
Here, however, we  use a very simple cell merger algorithm to force
all cells to have a volume at least as large as an uncut cell.

Given a cut cell $\ibold$, we define the box containing only that cell
$B_c = B(\ibold, \ibold)$ We form a $2^D$ cell rectangular region by
coarsening and then refining $B_c$ to form $B_v = R(C(B_c))$
\footnotemark[6].  After that process, any left over small cells are
merged with their biggest neighbor.  See figures
\ref{fig::unmerged2dmap} and \ref{fig::merged2dmap} for a simple
example of how this algorithm creates fairly chunky grids

Merging two cells is simply a matter of removing the
intervening faces, shifting all moments them to a common location
and adding them together.  No accuracy is lost in this process
outside of the fact that we have fewer degress of freedom because
semantically, we are just adding volume integrals over distinct
volumes, which is exact.

For unmerged grids, the volume fraction $\kappa_\ibold \equiv
V_\ibold/h^D$ can be arbitrarily small ($ 0 < \kappa <= 1$).
When merged using this algorithm, $\kappa$ can be larger than $2^D$.





\begin{figure}
\centerline{\epsfig{figure=_fig/merged.ps,width=0.4\linewidth } }
\caption{Map of EB grid shown in \ref{fig::unmerged2dmap} after using
  cell merger algorithm.
  Each cut cell has a unique positive integer. $ 1 <= \kappa <= 4.1433$}
\label{fig::merged2dmap}
\end{figure}

\section{Conclusions}
\section{Appendix:Cell Merger Algorithm}



\footnotetext[1]{Lawrence Berkeley National Laboratory, Berkeley,
  CA. Research at LBNL was supported financially by the Office of
  Advanced Scientific Computing Research of the US Department of
  Energy under contract number DE-AC02-05CH11231.}
\footnotetext[2]{Ford Motor Company, Sunnyvale, CA.}
\footnotetext[3]{If the matrix $M$ is square, a weighting matrix can
  have no effect and the Moore-Penrose psueudoinverse becomes
  $M^{-1}$.}

\footnotetext[4]{Defining $\xbar_\ibold = 0$, the
  equations for volumes $\jbold$ where $\xbar_\jbold$ target receive
  higher weights.  Diagonal weighting matricies are common.  Usually,
  these algorithms define a distance metric $D(\ibold, \jbold)$ for
  two volumes $\ibold$ and $\jbold$.  Typically they make
  $W_{\jbold,\jbold}$ decrease strongly with increasing 
  $D(\ibold,\jbold)$ to assign higher importance to the equations for volumes
  closer to $\ibold$.  Devendran for example \cite{Devendran2017},
  uses a weighting function that varies with $W_{\ibold,\jbold}
  \approx 1./D(\ibold,\jbold)^5$ }.


\footnotetext[6] {We mean a Box as defined in Chombo, a subset of
  $Z^D$.  Coarsening and refining has the standard Chombo semantic
  \cite{ChomboDesign, ChomboDesignEB}.}

\footnotetext[7] {All matrix computations here are performed using
  Eigen \cite{eigenweb}, a beautifully designed and implemented
  package for on-processor linear algebra that is freely available.}

\footnotetext[8]{The discerning reader will notice that
the equation set used to create $C$ only includes the volume
equations.  Devendran et al. \cite{Devendran2017} also include boundary
condition equations in the equation set.  For simple enough boundary
conditions, this works very well.  There are many equation sets,
however, which do not lend themselves easily to this approach.
Notably, hyperbolic equations often have boundary conditions which are
fomulated in terms of characteristic variables.  Using this
information in the system of equations for Taylor coefficients is
still a matter of research.  We therefore believe that restricting
ourselves to the volume equations can provide insight valuable to
developers of this class of algorithms.}

\renewcommand{\thefootnote}{\fnsymbol{footnote}}\
\bibliography{references}

\end{document}
